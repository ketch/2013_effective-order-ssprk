\section{Strong stability preserving Runge--Kutta methods}
\label{sec:SSP}

Strong stability preserving time-stepping methods were originally used
for time integration of hyperbolic conservation laws
\cite{Shu/Osher:1988} such as
\begin{align*}
    U_t + f(U)_x = 0,   % not bold: scalar PDE
\end{align*}
with appropriate initial and boundary conditions.
A spatial discretization gives the system of ODEs
\begin{align*}
    \bm{u}_{t} = \bm{F}(\bm{u}),
\end{align*}
where $\bm{u}$ is a vector of continuous-in-time grid values
approximating the solution $U$ at discrete grid points and $\bm{F}$ is
the spatial discretization. % of $f(U)_x$.
% TODO: do we need add something about F being more general than just HCL?
A time discretization then produces a sequence of solutions
$\bm{u}^{n} \approx \bm{u}(t_n)$.

Many popular spatial discretizations are chosen such that for a
suitable class of problems the solution $\bm{u}^{n}$ computed with the
forward Euler scheme
\begin{align}\label{eq:forwardEuler}
    \bm{u}^{n+1} = \bm{u}^{n} + \Dt\bm{F}(\bm{u}^{n}),
\end{align}
is non-increasing in some norm, seminorm, or convex functional:
\begin{align*}
    \|\bm{u}^{n+1}\| \le \|\bm{u}^n\|,
\end{align*}
for some time-step restriction $\Dt \leq \Dt_{\text{FE}}$.
If this is the case, then an SSP method also generates solutions which are non-increasing, under a modified time-step restriction.
\begin{definition}[Strong Stability Preserving]
Suppose $\bm{F}$ is a spatial discretization which satisfies
$$\|\bm{u}^{n} + \Dt\bm{F}(\bm{u}^{n})\| \le \|\bm{u}^n\|,$$
for all suitably-restricted time steps
$0 \le \Dt \le \Dt_{\text{FE}}$,
in a norm, seminorm, or convex functional $\|\cdot\|$ of interest.
Then a time-stepping method is said to be \emph{strong stability
  preserving} with \emph{SSP coefficient} $\sspcoef > 0$ if it
generates a sequence of solution values $\bm{u}^n$ such that
\begin{align*}
  \|\bm{u}^{n+1}\| \le \|\bm{u}^n\|,
\end{align*}
for a time-step restriction
$$\Dt \leq \sspcoef \Dt_{\text{FE}}.$$
\end{definition}


\subsection{The SSP coefficient}

The SSP coefficient $\sspcoef$ is a property of the particular time-stepping method and quantifies the allowable time step size relative to that of the forward Euler method
($\Dt_{\text{FE}}$ can be thought of as a property of the spatial discretization $\bm{F}$).
Generally we want the SSP coefficient to be as large as possible for efficiency.
To allow a fair comparison of different explicit methods, we scale by the number of stages $s$ by computing the \emph{effective SSP coefficient}
$$\ceff = \frac{\sspcoef}{s}.$$
Note the somewhat unfortunate terminology: the word \emph{effective} here is unrelated to the concept of \emph{effective order} introduced below.
%\yianniscomment{It is also unfortunately that we can't avoid referring to effective SSP coefficient. Perhaps this can be minimized only in the title of the table \ref{tab:5.1}}


%\subsection{Optimization of schemes}
\subsection{Optimal SSP schemes}
\label{subsec:Optimal_SSPRK}


An explicit $s$-stage Runge--Kutta method generates a sequence of approximate solutions $\bm{u}^n \approx \bm{u}(t_n)$ via an update formula
\begin{align*}
\bm{u}^{n+1} &= \bm{u}^{n} + \Dt \sum_i^s b_i \bm{F}(\bm{Y}_j), \\
\text{where} \quad \bm{Y}_{i} &= \bm{u}^{n} + \Dt \sum_j^s a_{ij} \bm{F}(\bm{Y}_i).
\end{align*}
For time dependent $\bm{F}$ we would also need nodes $c_i =
\sum_j^sa_{ij}$.
% where the $\bm{Y}^j$ are intermediate stage values.
This is the Butcher form of the Runge--Kutta method and the
coefficients $(A,\bm{b},\bm{c})$ make up the Butcher tableau
\cite{Butcher2008_book}.
For the method to obtain a certain order of accuracy, the coefficients must satisfy certain order conditions.
For the method to be SSP, it must have a strictly positive SSP
coefficient.

We say that an SSP Runge--Kutta method is optimal if it has the largest possible SSP coefficient for a given order and a given number of stages.
The search for these optimal methods was originally based on expressing the Runge--Kutta method as combinations of forward Euler steps (the Shu--Osher form) and solving a nonlinear optimization problem \cite{Gottlieb1998, Gottlieb2001, Spiteri2003a, Spiteri2003b, Ruuth2004}.
%The optimization process followed is similar with the one used in \cite{Ketcheson2008, Ketcheson2009} and the search for optimal explicit Runge-Kutta methods has been explored in \cite{Gottlieb1998, Gottlieb2001, Spiteri2003a, Spiteri2003b, Ruuth2004} by using the Shu-Osher form.
However, the SSP coefficient is related to the \emph{radius of absolute monotonicity} \cite{Kraaijevanger1991} and, for irreducible Runge--Kutta methods, the two are equivalent \cite{Ferracina2004, Higueras2004}.
This gives an algebraic characterization of the SSP coefficient.
The optimization problem of finding optimal SSP Runge--Kutta methods
can be written in terms of the coefficients $A$ and $\bm{b}$ as
follows:
\begin{equation}\label{eq:SSP_opt}
    \max_{A, \bm{b}, r} r, \qquad \text{subject to } \quad \left\{
                                                 \begin{array}{ll}
                                                   K(I + rA)^{-1} \geq 0 \\
                                                   \bm{e}_{s+1} - rK(I + rA)^{-1}\bm{e}_{s} \geq 0 \\
                                                   \Phi(K) = 0.
                                                 \end{array}
                                               \right.
\end{equation}
Here
\begin{equation*}
    K = \left(
            \begin{array}{c}
                     A              \\
                     \bm{b}^{\texttt{T}}
            \end{array}
         \right),
\end{equation*}
$\bm{e}_s$ denotes the vector of ones of length $s$,
and \( \Phi(K) \) represents the  order conditions.
The inequalities are understood component-wise.

Useful upper bounds for the above optimization problem can be obtained by consider an important relaxation. 
In the relaxed problem, the method is required to be accurate and strong stability preserving only for linear, constant-coefficient initial value problems. 
This leads to a reduced set of order conditions and a reduced set of absolute monotonicity conditions.
We denote the resulting optimal value by $\clin$; clearly for any method
\begin{equation*}
	\sspcoef\le\clin.
\end{equation*}
Exact optimal values of $\clin$ are known for many classes of methods; for example see \cite{Kraaijevanger1986,ketcheson2009a}.

Following \cite{Ketcheson2008, Ketcheson2009}, we will use the optimization problem \eqref{eq:SSP_opt} to perform a numerical search for optimal explicit SSP Runge--Kutta methods. 
However, we first need to define the order conditions $\Phi(K)$ for methods of effective order.
This is discussed in the next section.
