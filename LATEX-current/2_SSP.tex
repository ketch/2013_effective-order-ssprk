\section{Strong stability preserving Runge--Kutta methods}\label{sec:SSP}
Strong stability preserving (SSP) time-stepping methods were originally introduced
for time integration of systems of hyperbolic conservation laws
\cite{Shu/Osher:1988} 
\begin{align}\label{eq:pde}
	\bm{U}_t + \nabla \cdot \bm{f}(\bm{U}) = 0,   
\end{align}
with appropriate initial and boundary conditions.
A spatial discretization gives the system of ODEs
\begin{align}\label{eq:ode_system}
    \bm{u}'(t) = \bm{F}(t,\bm{u}(t)),
\end{align}
\colintodo{not sure making $\bm{F}$ time-dep is good idea: makes 
SSP defn harder?}
\yiannistodo{I don't think so, in general it can depend on time and 
later we say about a time-dependent F to define the nodes $c_j$. 
I suggest a definition for SSP in comments.}
where $\bm{u}$ is a vector of continuous-in-time grid values approximating 
the solution $\bm{U}$ at discrete grid points.
Of course, \eqref{eq:ode_system} can arise in many ways and $\bm{F}$
need not necessarily represent a spatial discretization.
In any case, a time discretization then produces a sequence of
solutions
$\bm{u}^{n} \approx \bm{u}(t_n)$ and in this work we study explicit 
Runge--Kutta time discretizations.
An explicit $s$-stage Runge--Kutta method takes the form
\begin{align*}
	\bm{u}^{n+1} &= \bm{u}^{n} + \Dt \sum_i^s b_i \bm{F}(t_n + c_i \Dt,\bm{Y}_i), \\
	\text{where} \quad \bm{Y}_i &= \bm{u}^{n} + \Dt \sum_j^{i-1} a_{ij} \bm{F}(t_n + c_j \Dt,\bm{Y}_j)
\end{align*}
and $c_i = \sum_j^sa_{ij}$.
The accuracy and stability of the method depend on the coefficients
$(A,\bm{b},\bm{c})$ \cite{Butcher2008_book}.

In some cases, the solutions of hyperbolic conservation laws satisfy a 
monotonicity property. For example, if \eqref{eq:pde} is scalar then solutions 
are monotonic in the total variation seminorm.
\colintodo{should motivate this better}
\yiannistodo{This is from David's paper \cite{Ketcheson2008}}
For this reason, many popular spatial discretizations are designed such 
that, for a suitable class of problems, the solution $\bm{u}^{n}$ 
computed with the forward Euler scheme
\begin{align}\label{eq:forwardEuler}
    \bm{u}^{n+1} = \bm{u}^{n} + \Dt\bm{F}(t,\bm{u}^{n}),
\end{align}
is non-increasing (in time)
in some norm, seminorm, or convex functional:
\begin{align*}
    \|\bm{u}^{n+1}\| \le \|\bm{u}^n\|, \; \forall \bm{u}
\end{align*}
\colintodo{definitely not ``$\forall u$'', maybe $\forall n$ but not sure why we need this}
\yiannistodo{Isn't that relate to `` $\DtFE$ is independent of $\bm{u}$"? Also it is mentioned later in the definition.}
subject to a time-step restriction $\Dt \leq \DtFE$.
Note that $\DtFE$ is independent of $\bm{u}$ and is a property of $\bm{F}$.
If this is the case, then an SSP method also generates a solution whose norm is
non-increasing in time, under a modified time-step restriction. 
\begin{definition}[Strong Stability Preserving]
	Suppose function $\bm{F}$, convex functional $\|\cdot\|$, and
	constant $\DtFE$ are such that
	%any possible values, any possibilities, arbitrary members of ...??
	% you not need to say
	\begin{align*}
		\|\bm{u} + \Dt\bm{F}(t,\bm{u})\| \le \|\bm{u}\|, \; \forall \bm{u}
		\text{ and  for all } \Dt \le \DtFE.
	\end{align*}
	Then a time-stepping method is said to be \emph{strong stability
  	preserving} with \emph{SSP coefficient} $\sspcoef > 0$ if it
	generates a sequence of solution values $\bm{u}^n$ such that
	\begin{align*}
  		\|\bm{u}^{n+1}\| \le \|\bm{u}^n\|,
	\end{align*}
	for a time-step restriction
	\begin{align*}
		\Dt \leq \sspcoef \DtFE.
	\end{align*}
\end{definition}
%\begin{definition}[Strong Stability Preserving]
%	Suppose that the Forward Euler method applied to \eqref{eq:pde} 
%	is strongly stable in a norm, seminorm or convex functional $\|\cdot\|$, i.e.
%	\begin{align*}
%		\|\bm{u}^{n} + \Dt\bm{F}(\bm{u}^{n})\| \le \|\bm{u}^n\|, \; \forall \bm{u},
%	\end{align*}
%	under suitably-restricted time steps $0 \le \Dt \le \DtFE$.
%	Then a high-order Runge--Kutta method is said to be \emph{strong stability
%  	preserving} with \emph{SSP coefficient} $\sspcoef > 0$ if it
%	generates a sequence of solution values $\bm{u}^n$ such that
%	\begin{align*}
%  		\|\bm{u}^{n+1}\| \le \|\bm{u}^n\|,
%	\end{align*}
%	for a time-step restriction
%	\begin{align*}
%		\Dt \leq \sspcoef \Dt_{\text{FE}}.
%	\end{align*}
%\end{definition} 
\davidtodo{In this definition, it seems that the SSP property of a method depends on the choice of $F$.  Now it's even worse -- why do we care if $F$ is a spatial discretization?}
\colintodo{Does this help?}
\colintodo{maybe want stage values SSP too...}
\yiannistodo{Colin made a suggestion and I have one in comments.}

The SSP coefficient $\sspcoef$ is a property of the particular
time-stepping method and quantifies the allowable time step size relative 
to that of the forward Euler method.
Generally we want the SSP coefficient to be as large as possible for efficiency.
To allow a fair comparison of different explicit methods, we consider the 
\emph{effective SSP coefficient}
\begin{align*}
	\ceff = \frac{\sspcoef}{s}.
\end{align*}
Note that the use of the word \emph{effective} here is unrelated to the 
concept of \emph{effective order} introduced in Section~\ref{sec:Algebraic_RK}.

\subsection{Optimal SSP schemes}\label{subsec:Optimal_SSPRK}
We say that an SSP Runge--Kutta method is optimal if it has the largest 
possible SSP coefficient for a given order and a given number of stages.
The search for these optimal methods was originally based on
expressing the Runge--Kutta method as combinations of forward Euler
steps (the Shu--Osher form) and solving a nonlinear optimization
problem \cite{Gottlieb/Shu:1998, Gottlieb2001, Spiteri2003a, Spiteri2003b, 
Ruuth2004, Ruuth:2006}.
However, the SSP coefficient is related to the 
\emph{radius of absolute monotonicity} \cite{Kraaijevanger1991} and, 
for irreducible Runge--Kutta methods, the two are equivalent 
\cite{Ferracina2004, Higueras2004}.
This gives a simplified algebraic characterization of the SSP coefficient
\cite{Ferracina2005}.
The optimization problem of finding optimal SSP Runge--Kutta methods
can be written in terms of the coefficients $A$ and $\bm{b}$ as
follows:
\begin{equation}\label{eq:SSP_opt}
    \max_{A, \bm{b}, r} \; r, \quad \text{subject to} \quad \left\{
                                                 \begin{array}{ll}
                                                   K(I + rA)^{-1} \geq 0 \\
                                                   \bm{e}_{s+1} - rK(I + rA)^{-1}\bm{e}_{s} \geq 0 \\
                                                   \Phi(K) = 0.
                                                 \end{array}
                                               \right.
\end{equation}
Here
\begin{equation*}
    K = \left(
            \begin{array}{c}
                     A              \\
                     \bm{b}^{\texttt{T}}
            \end{array}
         \right),
\end{equation*}
while $\bm{e}_s$ denotes the vector of ones of length $s$,
and \( \Phi(K) \) represents the  order conditions.
The inequalities are understood component-wise.

Useful upper bounds for the above optimization problem can be obtained 
by considering an important relaxation. 
In the relaxed problem, the method is required to be accurate and strong 
stability preserving only for linear, constant-coefficient initial value problems. 
This leads to a reduced set of order conditions and a relaxed absolute 
monotonicity condition.
We denote the SSP coefficient of a method for linear problems by $\clin$; 
clearly for any method
\begin{align*}
	\sspcoef\le\clin
\end{align*}
and the same inequality holds for the optimal coefficients over a given class.
Exact optimal values of $\clin$ are known for many classes of methods; for
example see \cite{Kraaijevanger1986,ketcheson2009a}.

Following \cite{Ketcheson2008, Ketcheson/Macdonald/Gottlieb:2009}, 
we will numerically solve the optimization problem \eqref{eq:SSP_opt} to find
optimal effective order explicit SSP Runge--Kutta methods.
\davidtodo{I think it would be better to move section 2.1 into section 5.}
\colintodo{Could do, I'm (yet) not convinced it matters.}
\yiannistodo{I think is better to leave it here. }
However, we first need to define the order conditions $\Phi(K)$ for methods
of effective order.
This is discussed in the next section.
% I didn't like this edit so I reverted it
% i didn't ike it too when I read it again and I wrote almost exactly what you did. 
